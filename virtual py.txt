# Activate the virtual environment  phyton
source ~/myenv/bin/activate
cd /var/www/html/ai/
deactivate


# پاک کردن داده‌های قبلی
rm -rf processed_data/parsicanada.com
# اجرای مجدد فاز 1
python run_phase1.py https://parsicanada.com --max-pages 20
# اجرای فاز 2
python run_phase2.py parsicanada.com --server --type gemini --port 5000
--type online: استفاده از OpenAI
--type local: استفاده از Ollama
--type gemini: استفاده از Google Gemini


# گام 1: ایجاد امبدینگ‌ها  
python create_embeddings.py  

# گام 2: ایجاد پایگاه دانش  
python create_knowledge_base.py  

# گام 3: تست پایگاه دانش  
python test_knowledge_base.py  

# گام 4: راه‌اندازی چت‌بات  
python chatbot_rag.py
python chatbot_rag_local.py --model llama3.2:latest

# گام 5 (اختیاری): راه‌اندازی سرور وب  
python app.py
python app.py --type gemini --port 5001
--type online: استفاده از OpenAI
--type local: استفاده از Ollama
--type gemini: استفاده از Google Gemini

# اجرای کامل فاز 2 بدون تست و سرور  
python run_phase2.py  

# اجرای کامل فاز 2 با تست پایگاه دانش  
python run_phase2.py --test  

# اجرای کامل فاز 2 و راه‌اندازی سرور وب  
python run_phase2.py --server  

# استفاده از پارامترهای سفارشی  
python run_phase2.py --input processed_data/final_processed_data.csv --model all-mpnet-base-v2 --test  




 
فازبندی بهبودها
فاز اول: شناسایی و حذف context بی‌ارزش (متن‌های عمومی، تکراری یا فاقد اطلاعات خاص)
فاز دوم: افزایش سخت‌گیری در همپوشانی (افزایش min_overlap و اضافه کردن phrase match)
فاز سوم: ثبت و لاگ false positiveها برای تحلیل و بهبود تدریجی فیلترها
فاز چهارم: استفاده از مدل یا قاعده برای تشخیص ارتباط واقعی context با سوال (مثلاً classifier ساده)
فاز پنجم: بهبود رنکینگ و ترکیب نتایج (استفاده از re-ranker قوی‌تر یا تنظیم وزن‌ها)
<hr></hr>
فاز اول: شناسایی و حذف context بی‌ارزش
هدف: جلوگیری از ارسال متن‌های عمومی، تکراری یا فاقد اطلاعات خاص به مدل زبانی، تا فقط contextهای واقعاً مرتبط و مفید باقی بمانند.  کارهایی که باید انجام شود:  
تعریف معیار برای context بی‌ارزش (مثلاً: فقط stopword، خیلی کوتاه، جملات تکراری، فاقد کلمات کلیدی سوال)
پیاده‌سازی یک تابع ساده برای تشخیص و حذف این contextها در متد get_relevant_context در فایل chatbot_rag.py
تست و بررسی خروجی برای چند سوال نمونه
مثال معیارها:  
اگر بیش از ۷۰٪ کلمات context stopword باشند → حذف شود
اگر طول متن کمتر از ۵۰ کاراکتر باشد → حذف شود
اگر context در چندین سوال تکرار شود (مثلاً hash آن قبلاً دیده شده) → حذف شود
در فاز اول فقط همین موارد را پیاده‌سازی و تست می‌کنیم. اگر موافق هستید، کد پیشنهادی برای این فاز را آماده می‌کنم.
